# ============================================================
# ENHANCED CATBOOST VERSION (Single Model, GPU-Friendly)
# ------------------------------------------------------------
# Goal:
#   - Much faster than 3-model stacking
#   - Enhanced feature engineering based on best practices
#   - No aggressive post-processing
#   - Reasonable MAEï¼Œé¿å…å†å‡ºç° 700+ è¿™ç§ç¾éš¾
#
# Enhanced Features:
#   - Detailed time features (year, month, day, season)
#   - Missing value indicators
#   - Outlier detection flags
#   - Brand-model combinations
#   - Frequency encoding for categorical features
#   - Statistical features (brand/model level stats within CV folds)
#   - Power-displacement ratio and other interaction features
#
# Files required (same folder as this script):
#   - used_car_train_20200313.csv
#   - used_car_testB_20200421.csv
#
# Run:
#   python train_fast_catboost_gpu.py
#
# Output:
#   price_prediction_fast_catboost.csv
# ============================================================

import os
import time
from datetime import datetime

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error

from catboost import CatBoostRegressor, Pool

# ------------------------------------------------------------
# 1. Paths & basic info
# ------------------------------------------------------------
base_dir = os.path.dirname(os.path.abspath(__file__))
train_file = os.path.join(base_dir, "used_car_train_20200313.csv")
test_file  = os.path.join(base_dir, "used_car_testB_20200421.csv")

print("\n=======================================================")
print("ğŸš— USED CAR PRICE â€” ENHANCED CATBOOST")
print("=======================================================")
print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# é»˜è®¤æ˜¯ç©ºæ ¼åˆ†éš”
train = pd.read_csv(train_file, sep=" ")
test  = pd.read_csv(test_file, sep=" ")

print(f"Train shape: {train.shape}, Test shape: {test.shape}")
print(f"Train columns: {list(train.columns[:8])} ...\n")

# ------------------------------------------------------------
# 2. Enhanced preprocessing / feature engineering
#    â€”â€” æ•´åˆé«˜çº§ç‰¹å¾å·¥ç¨‹ï¼Œæå‡æ¨¡å‹æ€§èƒ½
# ------------------------------------------------------------
def preprocess(df: pd.DataFrame, is_train: bool = True, km_clip: tuple = None, 
               outlier_clips: dict = None) -> tuple:
    df = df.copy()

    # 2.1 æ—¥æœŸè§£æ â†’ è¯¦ç»†æ—¶é—´ç‰¹å¾
    for col in ["regDate", "creatDate"]:
        df[col] = pd.to_datetime(df[col].astype(str), format="%Y%m%d", errors="coerce")
        # å¤„ç†æ— æ•ˆæ—¥æœŸ
        df.loc[df[col].isnull(), col] = pd.to_datetime('20160101', format='%Y%m%d')

    # è½¦è¾†å¹´é¾„ï¼ˆå¹´ï¼‰
    df["car_age"] = (df["creatDate"].dt.year - df["regDate"].dt.year)
    df["car_age"] = df["car_age"].clip(lower=0, upper=30)
    
    # è½¦è¾†å¹´é¾„ï¼ˆå¤©æ•°ï¼‰
    used_days = (df["creatDate"] - df["regDate"]).dt.days
    df["used_days"] = used_days.clip(lower=0, upper=365 * 30)
    df["vehicle_age_years"] = df["used_days"] / 365.0

    # æ³¨å†Œæ—¥æœŸç‰¹å¾
    df["reg_year"] = df["regDate"].dt.year
    df["reg_month"] = df["regDate"].dt.month
    df["reg_day"] = df["regDate"].dt.day
    df["reg_season"] = ((df["reg_month"] % 12 + 3) // 3).astype(int)
    
    # åˆ›å»ºæ—¥æœŸç‰¹å¾
    df["creat_year"] = df["creatDate"].dt.year
    df["creat_month"] = df["creatDate"].dt.month
    df["creat_day"] = df["creatDate"].dt.day
    df["creat_season"] = ((df["creat_month"] % 12 + 3) // 3).astype(int)
    
    # æ˜¯å¦ä¸ºæ–°è½¦
    df["is_new_car"] = (df["vehicle_age_years"] < 1).astype(int)
    
    # ç›¸å¯¹å½“å‰å¹´ä»½çš„è½¦é¾„
    current_year = datetime.now().year
    df["car_age_from_now"] = current_year - df["reg_year"]

    # 2.2 ç¼ºå¤±å€¼å¤„ç† - æ‰€æœ‰æ•°å€¼ç‰¹å¾
    numerical_features = ['power', 'kilometer', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 
                          'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14']
    for feature in numerical_features:
        if feature in df.columns:
            # æ ‡è®°ç¼ºå¤±å€¼
            if df[feature].isnull().any():
                df[f'{feature}_missing'] = df[feature].isnull().astype(int)
                # å¡«å……ç¼ºå¤±å€¼ï¼ˆä½¿ç”¨ä¸­ä½æ•°ï¼‰
                df[feature] = df[feature].fillna(df[feature].median())

    # 2.3 power / kilometer åŸºç¡€å‰ªè£ï¼ˆéå¸¸å…³é”®ï¼Œé˜²æ­¢æç«¯å€¼å¹²æ‰°ï¼‰
    if "power" in df.columns:
        df["power"] = df["power"].clip(20, 600)

    # ç”¨è®­ç»ƒé›†åˆ†ä½æ•°åšå‰ªè£ï¼Œæµ‹è¯•é›†ä½¿ç”¨è®­ç»ƒé›†çš„åˆ†ä½æ•°
    if is_train:
        km_low  = df["kilometer"].quantile(0.001)
        km_high = df["kilometer"].quantile(0.999)
        km_clip = (km_low, km_high)
    else:
        if km_clip is not None:
            km_low, km_high = km_clip
        else:
            km_low  = df["kilometer"].quantile(0.001)
            km_high = df["kilometer"].quantile(0.999)
    if "kilometer" in df.columns:
        df["kilometer"] = df["kilometer"].clip(km_low, km_high)

    # 2.3 notRepairedDamageï¼š'-' â†’ NaN â†’ {-1,0,1}
    if df["notRepairedDamage"].dtype == 'object':
        df["notRepairedDamage"] = df["notRepairedDamage"].replace("-", np.nan)
        df["notRepairedDamage"] = df["notRepairedDamage"].map({"0.0": 0, "1.0": 1, 0: 0, 1: 1, "0": 0, "1": 1})
    else:
        df["notRepairedDamage"] = df["notRepairedDamage"].replace("-", np.nan)
    df["notRepairedDamage"] = df["notRepairedDamage"].fillna(-1).astype(int)

    # 2.4 v_0 ~ v_14 ç»Ÿè®¡ç‰¹å¾
    v_cols = [c for c in df.columns if c.startswith("v_")]
    if v_cols:
        # ç»Ÿè®¡ç‰¹å¾
        df["v_mean"] = df[v_cols].mean(axis=1)
        df["v_std"]  = df[v_cols].std(axis=1)
        df["v_min"]  = df[v_cols].min(axis=1)
        df["v_max"]  = df[v_cols].max(axis=1)
        df["v_median"] = df[v_cols].median(axis=1)
        
        # åŠŸç‡ä¸æ’é‡æ¯”ï¼ˆå¦‚æœv_0å­˜åœ¨ï¼‰
        if "v_0" in df.columns:
            df["power_displacement_ratio"] = df["power"] / (df["v_0"] + 1)

    # 2.5 å¼‚å¸¸å€¼å¤„ç†ï¼ˆåŸºäºIQRæ–¹æ³•ï¼‰- å®é™…è£å‰ªå€¼ï¼Œä¸ä»…ä»…æ˜¯æ ‡å¿—
    # å‚è€ƒ feature_engineering_and_catboost.py çš„å®ç°
    numerical_cols_for_outlier = ['power', 'kilometer', 'v_0']
    outlier_clips_dict = {}
    
    for col in numerical_cols_for_outlier:
        if col in df.columns:
            if is_train:
                # è®­ç»ƒé›†ï¼šè®¡ç®—IQRå¹¶è£å‰ª
                Q1 = df[col].quantile(0.05)
                Q3 = df[col].quantile(0.95)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                outlier_clips_dict[col] = (lower_bound, upper_bound)
                
                # åˆ›å»ºå¼‚å¸¸å€¼æ ‡å¿—
                df[f'{col}_outlier'] = ((df[col] < lower_bound) | (df[col] > upper_bound)).astype(int)
                # å®é™…è£å‰ªå¼‚å¸¸å€¼
                df[col] = df[col].clip(lower_bound, upper_bound)
            else:
                # æµ‹è¯•é›†ï¼šä½¿ç”¨è®­ç»ƒé›†çš„è£å‰ªèŒƒå›´
                if outlier_clips is not None and col in outlier_clips:
                    lower_bound, upper_bound = outlier_clips[col]
                    # åˆ›å»ºå¼‚å¸¸å€¼æ ‡å¿—ï¼ˆåŸºäºè®­ç»ƒé›†çš„è¾¹ç•Œï¼‰
                    df[f'{col}_outlier'] = ((df[col] < lower_bound) | (df[col] > upper_bound)).astype(int)
                    # ä½¿ç”¨è®­ç»ƒé›†çš„è¾¹ç•Œè£å‰ª
                    df[col] = df[col].clip(lower_bound, upper_bound)
                else:
                    # Fallback: ä½¿ç”¨å½“å‰æ•°æ®çš„ç»Ÿè®¡é‡
                    Q1 = df[col].quantile(0.05)
                    Q3 = df[col].quantile(0.95)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    df[f'{col}_outlier'] = ((df[col] < lower_bound) | (df[col] > upper_bound)).astype(int)
                    df[col] = df[col].clip(lower_bound, upper_bound)

    # 2.6 è½¦è¾†ç‰¹å¾ç»„åˆ
    # modelè½¬æ¢ä¸ºæ•°å€¼å‹ï¼ˆç”¨äºç‰¹å¾ç»„åˆï¼‰
    if "model" in df.columns:
        df["model_num"] = df["model"].astype('category').cat.codes
    
    # å“ç‰Œä¸è½¦å‹ç»„åˆ
    if "brand" in df.columns and "model" in df.columns:
        df["brand_model"] = df["brand"].astype(str) + "_" + df["model"].astype(str)
    
    # ç‰¹å¾ç»„åˆ
    if "power" in df.columns and "model_num" in df.columns:
        df["power_model"] = df["power"] + df["model_num"]

    # 2.7 è¡ç”Ÿç‰¹å¾
    df["km_per_year"] = df["kilometer"] / (df["vehicle_age_years"] + 0.1)
    df["power_per_year"] = df["power"] / (df["vehicle_age_years"] + 0.1)
    df["km_x_age"] = df["kilometer"] * df["car_age"]
    df["power_x_age"] = df["power"] * df["car_age"]

    # 2.8 ä¸¢æ‰ä¸ç›´æ¥ç”¨äºå»ºæ¨¡çš„åˆ—
    drop_cols = ["regDate", "creatDate"]
    df = df.drop(columns=drop_cols, errors="ignore")

    return df, km_clip, outlier_clips_dict

# å…ˆæŠŠ price ç•™å‡ºæ¥
y = train["price"].copy()
train_proc, km_clip, outlier_clips = preprocess(train, is_train=True)
test_proc, _, _ = preprocess(test, is_train=False, km_clip=km_clip, outlier_clips=outlier_clips)

# ç›®æ ‡åˆ— price ä»…åœ¨ train
train_proc = train_proc.drop(columns=["price"])
# ç¡®ä¿ test æ²¡æœ‰ price
test_proc  = test_proc.drop(columns=["price"], errors="ignore")

# å¯¹é½åˆ—ï¼ˆäº¤é›†ï¼‰ï¼Œé˜²æ­¢åˆ—ä¸ä¸€è‡´
common_cols = sorted(list(set(train_proc.columns) & set(test_proc.columns)))
train_proc = train_proc[common_cols]
test_proc  = test_proc[common_cols]

# 2.9 é¢‘ç‡ç¼–ç ï¼ˆåœ¨åˆå¹¶å‰å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†åˆ†åˆ«å¤„ç†ï¼Œé¿å…æ•°æ®æ³„æ¼ï¼‰
print("åˆ›å»ºé¢‘ç‡ç¼–ç ç‰¹å¾...")
categorical_cols_for_freq = ["model", "brand", "bodyType", "fuelType", "gearbox", "notRepairedDamage"]
for col in categorical_cols_for_freq:
    if col in train_proc.columns:
        # ä½¿ç”¨è®­ç»ƒé›†çš„é¢‘ç‡æ¥ç¼–ç 
        freq_encoding = train_proc[col].value_counts() / len(train_proc)
        train_proc[f'{col}_freq'] = train_proc[col].map(freq_encoding).fillna(0)
        test_proc[f'{col}_freq'] = test_proc[col].map(freq_encoding).fillna(0)

# æ›´æ–° common_cols ä»¥åŒ…å«æ–°ç‰¹å¾
common_cols = sorted(list(set(train_proc.columns) & set(test_proc.columns)))
train_proc = train_proc[common_cols]
test_proc  = test_proc[common_cols]

# SaleID ä¸ä½œä¸ºç‰¹å¾
if "SaleID" in common_cols:
    common_cols.remove("SaleID")
    X_train = train_proc[common_cols].copy()
    X_test  = test_proc[common_cols].copy()
    test_saleid = test_proc["SaleID"].values
else:
    X_train = train_proc[common_cols].copy()
    X_test  = test_proc[common_cols].copy()
    test_saleid = test["SaleID"].values

print(f"ä½¿ç”¨ç‰¹å¾æ•°: {X_train.shape[1]}")
print(f"ç¤ºä¾‹ç‰¹å¾: {common_cols[:10]} ...\n")

# ------------------------------------------------------------
# 3. Add statistical features (within CV folds to avoid leakage)
# ------------------------------------------------------------
def add_statistical_features(X_tr, y_tr, X_val, X_test=None):
    """
    Add brand-level and model-level statistical features
    Computed only on training fold to avoid data leakage
    """
    X_tr = X_tr.copy()
    X_val = X_val.copy()
    if X_test is not None:
        X_test = X_test.copy()
    
    # Brand-level statistics
    if "brand" in X_tr.columns:
        brand_df = pd.DataFrame({"brand": X_tr["brand"], "price": y_tr.values})
        brand_stats = brand_df.groupby("brand").agg({
            "price": ["mean", "median", "std", "count"]
        })
        brand_stats.columns = ["brand_price_mean", "brand_price_median", "brand_price_std", "brand_count"]
        brand_stats = brand_stats.reset_index()
        
        X_tr = X_tr.merge(brand_stats, on="brand", how="left")
        X_val = X_val.merge(brand_stats, on="brand", how="left")
        if X_test is not None:
            X_test = X_test.merge(brand_stats, on="brand", how="left")
        
        # Fill missing values
        for col in ["brand_count", "brand_price_mean", "brand_price_median", "brand_price_std"]:
            if col in X_tr.columns:
                fill_val = X_tr[col].median() if X_tr[col].dtype in ['float64', 'int64'] else 0
                X_tr[col] = X_tr[col].fillna(fill_val)
                X_val[col] = X_val[col].fillna(fill_val)
                if X_test is not None:
                    X_test[col] = X_test[col].fillna(fill_val)
    
    # Model-level statistics
    if "model" in X_tr.columns:
        model_df = pd.DataFrame({"model": X_tr["model"], "price": y_tr.values})
        model_stats = model_df.groupby("model").agg({
            "price": ["mean", "median", "std", "count"]
        })
        model_stats.columns = ["model_price_mean", "model_price_median", "model_price_std", "model_count"]
        model_stats = model_stats.reset_index()
        
        X_tr = X_tr.merge(model_stats, on="model", how="left")
        X_val = X_val.merge(model_stats, on="model", how="left")
        if X_test is not None:
            X_test = X_test.merge(model_stats, on="model", how="left")
        
        # Fill missing values
        for col in ["model_count", "model_price_mean", "model_price_median", "model_price_std"]:
            if col in X_tr.columns:
                fill_val = X_tr[col].median() if X_tr[col].dtype in ['float64', 'int64'] else 0
                X_tr[col] = X_tr[col].fillna(fill_val)
                X_val[col] = X_val[col].fillna(fill_val)
                if X_test is not None:
                    X_test[col] = X_test[col].fillna(fill_val)
    
    if X_test is not None:
        return X_tr, X_val, X_test
    else:
        return X_tr, X_val

# ------------------------------------------------------------
# 4. CatBoost â€” å•æ¨¡å‹ï¼ŒGPU ä¼˜å…ˆï¼Œ5 æŠ˜ CV
# ------------------------------------------------------------
# æŒ‡å®šå“ªäº›åˆ—æ˜¯ç±»åˆ«ç‰¹å¾
cat_cols = ["model", "brand", "bodyType", "fuelType",
            "gearbox", "regionCode", "seller", "offerType", "name", "brand_model"]
cat_cols = [c for c in cat_cols if c in X_train.columns]

# CatBoost éœ€è¦æŠŠç±»åˆ«åˆ—è½¬æˆå­—ç¬¦ä¸²
for c in cat_cols:
    if c in X_train.columns:
        X_train[c] = X_train[c].astype(str)
    if c in X_test.columns:
        X_test[c]  = X_test[c].astype(str)

# Get cat_indices for initial GPU test
cat_indices = [X_train.columns.get_loc(c) for c in cat_cols if c in X_train.columns]

print(f"ç±»åˆ«ç‰¹å¾åˆ—: {cat_cols}\n")

# log1p å˜æ¢ç›®æ ‡ï¼Œé¢„æµ‹åå† expm1 å›æ¥
y_log = np.log1p(y)

# CatBoost å‚æ•° â€”â€” ç›¸æ¯”ä½ ä¹‹å‰çš„ 8 æŠ˜ 3 æ¨¡å‹ï¼Œè¿™é‡Œéå¸¸è½»é‡
cat_params = dict(
    loss_function="MAE",
    eval_metric="MAE",
    depth=7,
    learning_rate=0.03,
    iterations=2000,       # å•æ¨¡å‹ + GPUï¼Œ2000 è½®å¾ˆå¿«
    l2_leaf_reg=4.0,
    random_seed=42,
    verbose=200            # æ¯ 200 è½®æ‰“ä¸€è¡Œ
)

# å°è¯•ç”¨ GPUï¼Œå¤±è´¥å°±è‡ªåŠ¨é€€å› CPU
try:
    cat_params["task_type"] = "GPU"
    print("å°è¯•ä½¿ç”¨ GPU è®­ç»ƒ CatBoost ...")
    _tmp_model = CatBoostRegressor(**cat_params)
    # ç”¨ä¸€å°å—æ•°æ®è¯•è·‘ä¸€ä¸‹ï¼Œç¡®è®¤ GPU å¯ç”¨
    tmp_pool = Pool(X_train.head(200), y_log.head(200), cat_features=cat_indices)
    _tmp_model.fit(tmp_pool)
    print("âœ… GPU æ¨¡å¼å¯ç”¨")
except Exception as e:
    print(f"âš ï¸ GPU ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU. åŸå› : {str(e)[:80]} ...")
    cat_params["task_type"] = "CPU"

# æ­£å¼ 5 æŠ˜ CV
kf = KFold(n_splits=5, shuffle=True, random_state=42)
oof_log = np.zeros(len(X_train))
fold_maes = []

start_train = time.time()
for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train), 1):
    print(f"\nğŸ“Š Fold {fold}/5 ...")
    X_tr, X_val = X_train.iloc[tr_idx].copy(), X_train.iloc[val_idx].copy()
    y_tr, y_val = y_log.iloc[tr_idx], y_log.iloc[val_idx]
    
    # Add statistical features within fold (avoid data leakage)
    X_tr, X_val = add_statistical_features(X_tr, y_tr, X_val)
    
    # Update cat_indices after adding new features
    cat_cols_current = [c for c in cat_cols if c in X_tr.columns]
    cat_indices_fold = [X_tr.columns.get_loc(c) for c in cat_cols_current if c in X_tr.columns]
    
    # Ensure categorical columns are strings
    for c in cat_cols_current:
        if c in X_tr.columns:
            X_tr[c] = X_tr[c].astype(str)
        if c in X_val.columns:
            X_val[c] = X_val[c].astype(str)

    train_pool = Pool(X_tr, y_tr, cat_features=cat_indices_fold)
    val_pool   = Pool(X_val, y_val, cat_features=cat_indices_fold)

    model = CatBoostRegressor(**cat_params)
    # è¿™é‡Œç”¨ early_stopping_rounds=200ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼ŒåŒæ—¶ä¹ŸåŠ å¿«è®­ç»ƒ
    model.fit(
        train_pool,
        eval_set=val_pool,
        use_best_model=True,
        early_stopping_rounds=200
    )

    oof_log[val_idx] = model.predict(val_pool)
    fold_mae = mean_absolute_error(y.iloc[val_idx], np.expm1(oof_log[val_idx]))
    fold_maes.append(fold_mae)
    print(f"   Fold {fold} MAE: {fold_mae:.4f}")

total_oof_mae = mean_absolute_error(y, np.expm1(oof_log))
print("\n================ OOF ç»“æœ ================")
print(f"å„æŠ˜ MAE: {[round(m, 4) for m in fold_maes]}")
print(f"æ•´ä½“ OOF MAE: {total_oof_mae:.4f}")
print("ï¼ˆæ³¨æ„ï¼šè¿™æ˜¯è®­ç»ƒé›†ä¸Šçš„äº¤å‰éªŒè¯ MAEï¼Œç”¨äºå¤§è‡´è¯„ä¼°æ¨¡å‹ï¼Œä¸ç­‰äºçº¿ä¸Šåˆ†æ•°ï¼‰")
print("=========================================\n")
print(f"è®­ç»ƒè€—æ—¶: {(time.time() - start_train)/60:.1f} åˆ†é’Ÿï¼ˆä½ çš„ RTX 5070 ä¸Šä¼šæ›´å¿«ï¼‰")

# ------------------------------------------------------------
# 5. ç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®ï¼Œå†è®­ä¸€ä¸ªæœ€ç»ˆæ¨¡å‹ï¼Œç„¶åé¢„æµ‹ testB
# ------------------------------------------------------------
print("\nğŸš€ ä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®æ‹Ÿåˆæœ€ç»ˆæ¨¡å‹ï¼Œå¹¶é¢„æµ‹æµ‹è¯•é›† ...")

# Add statistical features on full training set
X_train_final, _, X_test_final = add_statistical_features(X_train.copy(), y_log, X_test.copy(), X_test.copy())

# Update cat_indices for final model
cat_cols_final = [c for c in cat_cols if c in X_train_final.columns]
cat_indices_final = [X_train_final.columns.get_loc(c) for c in cat_cols_final if c in X_train_final.columns]

# Ensure categorical columns are strings
for c in cat_cols_final:
    if c in X_train_final.columns:
        X_train_final[c] = X_train_final[c].astype(str)
    if c in X_test_final.columns:
        X_test_final[c] = X_test_final[c].astype(str)

full_pool = Pool(X_train_final, y_log, cat_features=cat_indices_final)
final_model = CatBoostRegressor(**cat_params)
final_model.fit(full_pool)

test_pool = Pool(X_test_final, cat_features=cat_indices_final)
pred_log_test = final_model.predict(test_pool)
pred_test = np.expm1(pred_log_test)

# ç®€å•å®‰å…¨å‰ªè£ï¼ˆä¸è¦åƒä¹‹å‰é‚£æ ·çæ”¾å¤§ / æ”¶ç¼©ï¼‰
pred_test = np.clip(pred_test, 200, 300000)

# ------------------------------------------------------------
# 5. ä¿å­˜æäº¤ & ç®€å•åˆ†å¸ƒæ£€æŸ¥
# ------------------------------------------------------------
sub = pd.DataFrame({
    "SaleID": test_saleid,
    "price": pred_test
})

print("\nğŸ“ˆ Prediction distribution (testB ä¸Šçš„é¢„æµ‹åˆ†å¸ƒ):")
print(sub["price"].describe([0.01, 0.05, 0.95, 0.99]))

print("\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
print(f"  Mean: {sub['price'].mean():.2f}")
print(f"  Std : {sub['price'].std():.2f}")
print(f"  Min : {sub['price'].min():.2f}")
print(f"  Max : {sub['price'].max():.2f}")

out_file = os.path.join(base_dir, "price_prediction_fast_catboost.csv")
sub.to_csv(out_file, index=False, encoding="utf-8-sig")

print(f"\nğŸ’¾ å·²ä¿å­˜æäº¤æ–‡ä»¶: {out_file}")
print(f"å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("ğŸ¯ ENHANCED CATBOOST VERSION å®Œæˆ (with advanced feature engineering)")
